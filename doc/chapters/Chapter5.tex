\section{Learning Set}
The \textbf{preparation phase} focused on isolating a coherent baseline cohort, restructuring the heterogeneous \textit{ADNIMERGE.csv} into an analyzable form, and enforcing clinically sound data standards. The raw dataset, originally \textbf{visitâ€“centric} and affected by extensive missingness, redundant attributes, and inconsistencies across ADNI phases, was reduced to a strictly \textbf{baseline-oriented structure} in which each participant contributes a single, diagnostically reliable record. 

A first objective was to ensure diagnostic consistency. Screening and baseline labels were reconciled to guarantee that each subject possesses a unique and clinically valid baseline diagnosis. This step was essential for framing the downstream problem as a cross-sectional classification task. Demographic attributes were then harmonized: ethnicity and race were merged into a compact demographic descriptor, marital status was simplified into an informative binary form, and sex was encoded to support normalization and group comparisons. These operations provided a unified representation while preserving clinically relevant distinctions.

Attributes with overwhelming missingness or with limited value for single-visit modelling were removed. The retained variables concentrated on demographics, genetic risk, cognition, CSF biomarkers, and structural MRI measurements. Biomarker fields containing detection-limit symbols were converted into usable quantitative values, ensuring numerical compatibility without distorting their clinical meaning. Categorical labels exhibiting inconsistencies across ADNI phases were standardized to a homogeneous nomenclature.

A \textbf{systematic assessment of numerical plausibility} led to the identification of \textit{outliers} that could not be justified clinically. Implausible values in cognitive tests and structural MRI volumes were marked for later imputation rather than corrected ad hoc, thereby \textbf{avoiding data leakage}. 

After consolidation, the resulting dataset forms a compact \textbf{learning set} explicitly designed for multiclassification. The final structure is well aligned with the goals of diagnostic modelling: it is coherent, interpretable, statistically stable, and it supports principled preprocessing steps. At the end I used the \textbf{Holdout Method} to split the data into 80\% for the training set and 20\% for the testing set. 
