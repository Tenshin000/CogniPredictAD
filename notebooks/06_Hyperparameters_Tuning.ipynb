{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ve selected our classification models, but we can't dive right into classification. The next challenge is to optimize the model construction. Since we’re working with a small dataset, the main risk is overfitting. To address this, we’ll apply hyperparameter tuning using **Grid Search**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from CogniPredictAD.visualization import Visualizer\n",
    "from CogniPredictAD.preprocessing import ADNIPreprocessor\n",
    "\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from scipy.stats import wilcoxon\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 116)\n",
    "pd.set_option(\"display.max_columns\", 40)\n",
    "pd.set_option(\"display.max_info_columns\", 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset\n",
    "Open the training dataset with Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1934, 47)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PTGENDER</th>\n",
       "      <th>PTEDUCAT</th>\n",
       "      <th>APOE4</th>\n",
       "      <th>CDRSB</th>\n",
       "      <th>ADAS11</th>\n",
       "      <th>ADAS13</th>\n",
       "      <th>ADASQ4</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>RAVLT_immediate</th>\n",
       "      <th>RAVLT_learning</th>\n",
       "      <th>RAVLT_forgetting</th>\n",
       "      <th>RAVLT_perc_forgetting</th>\n",
       "      <th>LDELTOTAL</th>\n",
       "      <th>TRABSCOR</th>\n",
       "      <th>FAQ</th>\n",
       "      <th>mPACCdigit</th>\n",
       "      <th>mPACCtrailsB</th>\n",
       "      <th>Ventricles</th>\n",
       "      <th>...</th>\n",
       "      <th>EcogPtMem</th>\n",
       "      <th>EcogPtLang</th>\n",
       "      <th>EcogPtVisspat</th>\n",
       "      <th>EcogPtPlan</th>\n",
       "      <th>EcogPtOrgan</th>\n",
       "      <th>EcogPtDivatt</th>\n",
       "      <th>EcogPtTotal</th>\n",
       "      <th>EcogSPMem</th>\n",
       "      <th>EcogSPLang</th>\n",
       "      <th>EcogSPVisspat</th>\n",
       "      <th>EcogSPPlan</th>\n",
       "      <th>EcogSPOrgan</th>\n",
       "      <th>EcogSPDivatt</th>\n",
       "      <th>EcogSPTotal</th>\n",
       "      <th>ABETA</th>\n",
       "      <th>TAU</th>\n",
       "      <th>PTAU</th>\n",
       "      <th>FDG</th>\n",
       "      <th>PTDEMOGROUP</th>\n",
       "      <th>MARRIED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD</td>\n",
       "      <td>80.9</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>29.33</td>\n",
       "      <td>42.33</td>\n",
       "      <td>10.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-20.06920</td>\n",
       "      <td>-18.356400</td>\n",
       "      <td>62224.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.14286</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.50000</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.94595</td>\n",
       "      <td>4.000</td>\n",
       "      <td>3.44444</td>\n",
       "      <td>2.66667</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>3.66667</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.47222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.04262</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LMCI</td>\n",
       "      <td>82.2</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>12.33</td>\n",
       "      <td>20.33</td>\n",
       "      <td>5.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>83.3333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-10.20060</td>\n",
       "      <td>-10.777900</td>\n",
       "      <td>85816.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.08058</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LMCI</td>\n",
       "      <td>71.2</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-18.1818</td>\n",
       "      <td>2.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.90200</td>\n",
       "      <td>-6.457590</td>\n",
       "      <td>38223.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.75000</td>\n",
       "      <td>2.55556</td>\n",
       "      <td>2.28571</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.83333</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.92308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.41455</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CN</td>\n",
       "      <td>75.5</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.19941</td>\n",
       "      <td>3.001880</td>\n",
       "      <td>61111.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75000</td>\n",
       "      <td>1.33333</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.16667</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.25641</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>762.0</td>\n",
       "      <td>200.6</td>\n",
       "      <td>18.84</td>\n",
       "      <td>1.11882</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CN</td>\n",
       "      <td>81.5</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>7.67</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.5714</td>\n",
       "      <td>11.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.16303</td>\n",
       "      <td>-0.101632</td>\n",
       "      <td>44690.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.87500</td>\n",
       "      <td>1.55556</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.33333</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.44737</td>\n",
       "      <td>1.375</td>\n",
       "      <td>1.11111</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.20000</td>\n",
       "      <td>1.16667</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.23684</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>LMCI</td>\n",
       "      <td>64.6</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-10.37820</td>\n",
       "      <td>-9.369810</td>\n",
       "      <td>28016.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>588.0</td>\n",
       "      <td>417.1</td>\n",
       "      <td>39.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1930</th>\n",
       "      <td>LMCI</td>\n",
       "      <td>82.9</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>13.33</td>\n",
       "      <td>23.33</td>\n",
       "      <td>9.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>42.8571</td>\n",
       "      <td>5.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.18102</td>\n",
       "      <td>-7.013430</td>\n",
       "      <td>48243.3</td>\n",
       "      <td>...</td>\n",
       "      <td>2.12500</td>\n",
       "      <td>1.12500</td>\n",
       "      <td>1.16667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.50000</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.78378</td>\n",
       "      <td>2.625</td>\n",
       "      <td>1.62500</td>\n",
       "      <td>1.16667</td>\n",
       "      <td>1.40000</td>\n",
       "      <td>1.83333</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.81081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.06861</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>LMCI</td>\n",
       "      <td>76.8</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.33</td>\n",
       "      <td>16.33</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.6667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.94141</td>\n",
       "      <td>-10.624000</td>\n",
       "      <td>29502.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>874.1</td>\n",
       "      <td>153.2</td>\n",
       "      <td>13.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>LMCI</td>\n",
       "      <td>74.6</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.00</td>\n",
       "      <td>27.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-13.05080</td>\n",
       "      <td>-10.521600</td>\n",
       "      <td>78282.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.87500</td>\n",
       "      <td>1.33333</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.33333</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.33333</td>\n",
       "      <td>3.125</td>\n",
       "      <td>2.87500</td>\n",
       "      <td>1.85714</td>\n",
       "      <td>1.33333</td>\n",
       "      <td>2.25000</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.55882</td>\n",
       "      <td>520.3</td>\n",
       "      <td>350.2</td>\n",
       "      <td>32.49</td>\n",
       "      <td>1.11678</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933</th>\n",
       "      <td>EMCI</td>\n",
       "      <td>72.7</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.22386</td>\n",
       "      <td>-7.956940</td>\n",
       "      <td>93560.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.12500</td>\n",
       "      <td>1.66667</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.16667</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.51282</td>\n",
       "      <td>1.750</td>\n",
       "      <td>1.71429</td>\n",
       "      <td>1.20000</td>\n",
       "      <td>1.25000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.38235</td>\n",
       "      <td>731.4</td>\n",
       "      <td>230.3</td>\n",
       "      <td>24.90</td>\n",
       "      <td>1.01818</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1934 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DX   AGE  PTGENDER  PTEDUCAT  APOE4  CDRSB  ADAS11  ADAS13  ADASQ4  \\\n",
       "0       AD  80.9         1        14    0.0    6.5   29.33   42.33    10.0   \n",
       "1     LMCI  82.2         1        20    0.0    1.5   12.33   20.33     5.0   \n",
       "2     LMCI  71.2         1        19    0.0    1.0    6.00    8.00     2.0   \n",
       "3       CN  75.5         0        20    0.0    0.0    3.00    6.00     3.0   \n",
       "4       CN  81.5         0        19    0.0    0.0    3.67    7.67     3.0   \n",
       "...    ...   ...       ...       ...    ...    ...     ...     ...     ...   \n",
       "1929  LMCI  64.6         0        14    2.0    2.0   12.00   22.00    10.0   \n",
       "1930  LMCI  82.9         1        18    0.0    1.5   13.33   23.33     9.0   \n",
       "1931  LMCI  76.8         1        12    0.0    1.0   11.33   16.33     4.0   \n",
       "1932  LMCI  74.6         1        19    1.0    2.0   17.00   27.00    10.0   \n",
       "1933  EMCI  72.7         1        14    1.0    0.5    8.00   15.00     7.0   \n",
       "\n",
       "      MMSE  RAVLT_immediate  RAVLT_learning  RAVLT_forgetting  \\\n",
       "0     21.0             15.0             1.0               3.0   \n",
       "1     24.0             29.0             0.0               5.0   \n",
       "2     26.0             51.0             2.0              -2.0   \n",
       "3     30.0             61.0             7.0               3.0   \n",
       "4     29.0             54.0             7.0               4.0   \n",
       "...    ...              ...             ...               ...   \n",
       "1929  27.0             31.0             1.0               7.0   \n",
       "1930  28.0             33.0             1.0               3.0   \n",
       "1931  25.0             27.0             2.0               1.0   \n",
       "1932  26.0             32.0             1.0               7.0   \n",
       "1933  26.0             25.0             0.0               1.0   \n",
       "\n",
       "      RAVLT_perc_forgetting  LDELTOTAL  TRABSCOR   FAQ  mPACCdigit  \\\n",
       "0                  100.0000        0.0     300.0  19.0   -20.06920   \n",
       "1                   83.3333        2.0     155.0   4.0   -10.20060   \n",
       "2                  -18.1818        2.0     106.0   2.0    -5.90200   \n",
       "3                   20.0000       19.0      58.0   0.0     3.19941   \n",
       "4                   28.5714       11.0      54.0   0.0    -1.16303   \n",
       "...                     ...        ...       ...   ...         ...   \n",
       "1929               100.0000        0.0      62.0   9.0   -10.37820   \n",
       "1930                42.8571        5.0      79.0   1.0    -9.18102   \n",
       "1931                16.6667        3.0     300.0   1.0    -9.94141   \n",
       "1932               100.0000        3.0     102.0   8.0   -13.05080   \n",
       "1933                25.0000        7.0     116.0   1.0    -9.22386   \n",
       "\n",
       "      mPACCtrailsB  Ventricles  ...  EcogPtMem  EcogPtLang  EcogPtVisspat  \\\n",
       "0       -18.356400     62224.0  ...    3.14286     3.00000        3.00000   \n",
       "1       -10.777900     85816.0  ...        NaN         NaN            NaN   \n",
       "2        -6.457590     38223.0  ...    2.75000     2.55556        2.28571   \n",
       "3         3.001880     61111.0  ...    1.75000     1.33333        1.00000   \n",
       "4        -0.101632     44690.2  ...    1.87500     1.55556        1.00000   \n",
       "...            ...         ...  ...        ...         ...            ...   \n",
       "1929     -9.369810     28016.0  ...        NaN         NaN            NaN   \n",
       "1930     -7.013430     48243.3  ...    2.12500     1.12500        1.16667   \n",
       "1931    -10.624000     29502.0  ...        NaN         NaN            NaN   \n",
       "1932    -10.521600     78282.0  ...    1.87500     1.33333        1.00000   \n",
       "1933     -7.956940     93560.0  ...    2.12500     1.66667        1.00000   \n",
       "\n",
       "      EcogPtPlan  EcogPtOrgan  EcogPtDivatt  EcogPtTotal  EcogSPMem  \\\n",
       "0            3.2      2.50000          2.75      2.94595      4.000   \n",
       "1            NaN          NaN           NaN          NaN        NaN   \n",
       "2            3.2      3.83333          3.50      2.92308        NaN   \n",
       "3            1.0      1.16667          1.00      1.25641      1.000   \n",
       "4            1.0      1.33333          1.75      1.44737      1.375   \n",
       "...          ...          ...           ...          ...        ...   \n",
       "1929         NaN          NaN           NaN          NaN        NaN   \n",
       "1930         2.0      2.50000          2.00      1.78378      2.625   \n",
       "1931         NaN          NaN           NaN          NaN        NaN   \n",
       "1932         1.2      1.33333          1.00      1.33333      3.125   \n",
       "1933         1.0      1.16667          2.00      1.51282      1.750   \n",
       "\n",
       "      EcogSPLang  EcogSPVisspat  EcogSPPlan  EcogSPOrgan  EcogSPDivatt  \\\n",
       "0        3.44444        2.66667     3.00000      3.66667          3.75   \n",
       "1            NaN            NaN         NaN          NaN           NaN   \n",
       "2            NaN            NaN         NaN          NaN           NaN   \n",
       "3        1.00000        1.00000     1.00000      1.00000          1.00   \n",
       "4        1.11111        1.00000     1.20000      1.16667          1.75   \n",
       "...          ...            ...         ...          ...           ...   \n",
       "1929         NaN            NaN         NaN          NaN           NaN   \n",
       "1930     1.62500        1.16667     1.40000      1.83333          2.00   \n",
       "1931         NaN            NaN         NaN          NaN           NaN   \n",
       "1932     2.87500        1.85714     1.33333      2.25000          3.25   \n",
       "1933     1.71429        1.20000     1.25000      1.00000          1.00   \n",
       "\n",
       "      EcogSPTotal  ABETA    TAU   PTAU      FDG  PTDEMOGROUP  MARRIED  \n",
       "0         3.47222    NaN    NaN    NaN  1.04262            6        0  \n",
       "1             NaN    NaN    NaN    NaN  1.08058            6        1  \n",
       "2             NaN    NaN    NaN    NaN  1.41455            6        1  \n",
       "3         1.00000  762.0  200.6  18.84  1.11882            6        1  \n",
       "4         1.23684    NaN    NaN    NaN      NaN            6        1  \n",
       "...           ...    ...    ...    ...      ...          ...      ...  \n",
       "1929          NaN  588.0  417.1  39.86      NaN            6        1  \n",
       "1930      1.81081    NaN    NaN    NaN  1.06861            6        1  \n",
       "1931          NaN  874.1  153.2  13.45      NaN            6        1  \n",
       "1932      2.55882  520.3  350.2  32.49  1.11678            6        1  \n",
       "1933      1.38235  731.4  230.3  24.90  1.01818            6        1  \n",
       "\n",
       "[1934 rows x 47 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Open the dataset with pandas\n",
    "dataset = pd.read_csv(\"../data/pretrain.csv\")\n",
    "viz = Visualizer(dataset)\n",
    "display(dataset.shape)\n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Class from Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = dataset['DX']\n",
    "X_train = dataset.drop(columns=['DX'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADNIPreprocessor Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the *Data Preprocessing notebook*, we developed a class that reproduces all its data-cleaning operations, ensuring consistent preprocessing for proper cross-validation evaluation.\n",
    "\n",
    "**`ADNIPreprocessor`** is a scikit-learn–compatible transformer for ADNI data preprocessing. It detects and converts integer-like columns, scales and imputes missing values with KNN, creates safe ratio variables, and normalizes MRI measures by intracranial volume (ICV). It can also perform optional hybrid class balancing with undersampling and SMOTENC oversampling.\n",
    "\n",
    "During fitting, the class computes means and standard deviations for numeric features and detects integer-like columns. The transform step applies imputation, integer conversion, ratio creation (`TAU/ABETA`, `PTAU/ABETA`), and MRI normalization, then removes redundant features. \n",
    "\n",
    "Core methods include `fit`, `transform`, `fit_transform`, and `get_feature_names_out`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = ADNIPreprocessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model Choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our classification model choices will be: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'Decision Tree': Pipeline([\n",
    "        ('pre', preprocessing), \n",
    "        ('clf', DecisionTreeClassifier(random_state=42, class_weight='balanced', max_depth=5))\n",
    "    ]),\n",
    "    'Random Forest': Pipeline([\n",
    "        ('pre', preprocessing),\n",
    "        ('clf', RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1))\n",
    "    ]),\n",
    "    'Extra Trees': Pipeline([\n",
    "        ('pre', preprocessing),\n",
    "        ('clf', ExtraTreesClassifier(random_state=42, class_weight='balanced', n_jobs=-1))\n",
    "    ]),\n",
    "    'Adaptive Boosting': Pipeline([\n",
    "        ('pre', preprocessing),\n",
    "        ('clf', AdaBoostClassifier(random_state=42, estimator=DecisionTreeClassifier(class_weight='balanced')))\n",
    "    ]),\n",
    "    'Multinomial Logistic Regression': Pipeline([\n",
    "        ('pre', preprocessing),\n",
    "        ('scl', StandardScaler()), \n",
    "        ('clf', LogisticRegression(random_state=42, solver='saga', max_iter=2000, class_weight='balanced'))\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to select parameters that maximize model performance while reducing the risk of overfitting. Since the dataset is small and the risk of overfitting is high, we will carefully select the best hyperparameters using **Grid Search**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gridsearch(X_train, y_train, pipelines, param_grids, cv=5, scoring='balanced_accuracy'):\n",
    "    \"\"\"\n",
    "    Runs GridSearchCV on multiple classifiers with their respective parameter grids.\n",
    "    Ignores classifiers that fail during fitting and continues with the others.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train : DataFrame or array\n",
    "        Training features.\n",
    "    y_train : Series or array\n",
    "        Training labels.\n",
    "    pipelines : dict\n",
    "        Dictionary with model names as keys and pipeline objects as values.\n",
    "    param_grids : dict\n",
    "        Dictionary with model names as keys and parameter grids as values.\n",
    "    cv : int, default=5\n",
    "        Number of folds for cross-validation.\n",
    "    scoring : str, default='balanced_accuracy'\n",
    "        Scoring metric to optimize.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    best_models : dict\n",
    "        Dictionary containing best estimator, parameters, and score for each classifier.\n",
    "    \"\"\"\n",
    "    best_models = {}\n",
    "    errors = {}\n",
    "    cv_scores = {}\n",
    "    \n",
    "    # GridSearch by model\n",
    "    for name, clf in pipelines.items():\n",
    "        print(f\"\\nRunning GridSearch for {name} ...\")\n",
    "        param_grid = param_grids.get(name, {})\n",
    "        \n",
    "        grid = GridSearchCV(\n",
    "            estimator=clf,\n",
    "            param_grid=param_grid,\n",
    "            cv=cv,\n",
    "            scoring=scoring,\n",
    "            n_jobs=-1,\n",
    "            verbose=1,\n",
    "            error_score='raise'\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            grid.fit(X_train, y_train)\n",
    "            best_models[name] = {\n",
    "                \"best_estimator\": grid.best_estimator_,\n",
    "                \"best_params\": grid.best_params_,\n",
    "                \"best_score\": grid.best_score_\n",
    "            }\n",
    "            print(f\"Best params for {name}: {grid.best_params_}\")\n",
    "            print(f\"Best {scoring}: {grid.best_score_:.4f}\")\n",
    "            \n",
    "            # Save fold-by-fold cross-validation scores on the best model\n",
    "            best_clf = grid.best_estimator_\n",
    "            scores = cross_val_score(best_clf, X_train, y_train, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "            cv_scores[name] = scores\n",
    "            print(f\"{name} CV scores: {scores}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Classifier {name} failed: {e}\")\n",
    "            errors[name] = str(e)\n",
    "    \n",
    "    return best_models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`run_gridsearch` takes a *training dataset*, a set of *classifiers*, and their respective *grid_params* and applies **GridSearchCV** to each model. For each classifier, it constructs a grid search with the chosen metric and cross-validation, executes it, prints the best parameters and score, and returns a dictionary that collects the best trained estimator, the optimal parameters, and the corresponding performance for each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the parameter grid to compare for the classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    'Decision Tree': {\n",
    "        'clf__criterion': ['gini', 'entropy'],\n",
    "        'clf__min_samples_split': [2, 4, 8],\n",
    "        'clf__min_samples_leaf': [2, 4, 8],\n",
    "        'clf__ccp_alpha': [0.0, 0.001, 0.005, 0.01, 0.05]\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'clf__n_estimators': [50, 75, 100],\n",
    "        'clf__max_depth': [None, 6, 4],\n",
    "        'clf__min_samples_leaf': [2, 4, 8],\n",
    "        'clf__max_features': [0.5, 0.8, 1.0, 'sqrt'],\n",
    "        'clf__criterion': ['gini', 'entropy']\n",
    "    },\n",
    "    'Extra Trees': {\n",
    "        'clf__n_estimators': [50, 75, 100],\n",
    "        'clf__max_depth': [None, 6, 4],\n",
    "        'clf__min_samples_leaf': [2, 4, 8],\n",
    "        'clf__max_features': [0.5, 0.8, 1.0, 'sqrt'],\n",
    "        'clf__criterion': ['gini', 'entropy']\n",
    "    },\n",
    "    'Adaptive Boosting': {\n",
    "        'clf__n_estimators': [50, 75, 100],\n",
    "        'clf__learning_rate': [0.01, 0.05, 0.1,],\n",
    "        'clf__estimator__max_depth': [None, 6, 4],\n",
    "        'clf__estimator__min_samples_leaf': [2, 4, 8],\n",
    "        'clf__estimator__criterion': ['gini', 'entropy']\n",
    "    },\n",
    "    'Multinomial Logistic Regression': {\n",
    "        'clf__C': [0.01, 0.1, 1.0, 10.0],\n",
    "        'clf__penalty': ['l1', 'l2']\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do **5-fold cross validation**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cross_validation = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the **F1 macro** score. It evaluates the unweighted average of the F1s per class, forcing the grid search to look for hyperparameters that balance precision/recall across all classes (it avoids optimizing a model that only \"exploits\" sparse features to predict the majority class). \n",
    "\n",
    "Now let's run the Grid Search (this will take a while)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running GridSearch for Decision Tree ...\n",
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
      "Best params for Decision Tree: {'clf__ccp_alpha': 0.005, 'clf__criterion': 'entropy', 'clf__min_samples_leaf': 8, 'clf__min_samples_split': 2}\n",
      "Best f1_macro: 0.9062\n",
      "Decision Tree CV scores: [0.91334176 0.89529202 0.90040767 0.90857668 0.91316229]\n",
      "\n",
      "Running GridSearch for Random Forest ...\n",
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "Best params for Random Forest: {'clf__criterion': 'entropy', 'clf__max_depth': 6, 'clf__max_features': 1.0, 'clf__min_samples_leaf': 4, 'clf__n_estimators': 100}\n",
      "Best f1_macro: 0.9180\n",
      "Random Forest CV scores: [0.90835019 0.92199984 0.92498265 0.93386079 0.90096899]\n",
      "\n",
      "Running GridSearch for Extra Trees ...\n",
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "Best params for Extra Trees: {'clf__criterion': 'entropy', 'clf__max_depth': None, 'clf__max_features': 1.0, 'clf__min_samples_leaf': 4, 'clf__n_estimators': 75}\n",
      "Best f1_macro: 0.9134\n",
      "Extra Trees CV scores: [0.89803812 0.91383346 0.93190715 0.93479767 0.88842301]\n",
      "\n",
      "Running GridSearch for Adaptive Boosting ...\n",
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "Best params for Adaptive Boosting: {'clf__estimator__criterion': 'gini', 'clf__estimator__max_depth': 4, 'clf__estimator__min_samples_leaf': 4, 'clf__learning_rate': 0.1, 'clf__n_estimators': 50}\n",
      "Best f1_macro: 0.9155\n",
      "Adaptive Boosting CV scores: [0.90211365 0.92231683 0.9286635  0.92644522 0.89794772]\n",
      "\n",
      "Running GridSearch for Multinomial Logistic Regression ...\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Best params for Multinomial Logistic Regression: {'clf__C': 0.1, 'clf__penalty': 'l1'}\n",
      "Best f1_macro: 0.8688\n",
      "Multinomial Logistic Regression CV scores: [0.8663792  0.86153871 0.87459711 0.88852663 0.85303541]\n"
     ]
    }
   ],
   "source": [
    "bmc = run_gridsearch(X_train=X_train, y_train=y_train, pipelines=classifiers, param_grids=param_grids, cv = n_cross_validation, scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the **F1 macro** score. Accuracy becomes meaningless because balancing alters the original distribution, thus not reflecting actual performance. F1 macro score evaluates precision and recall for each class separately, gives equal weight to all classes, and is not affected by artificial balancing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We re-write the pipelines for the sampling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\n",
    "    X_train.columns.get_loc(\"PTGENDER\"),\n",
    "    X_train.columns.get_loc(\"APOE4\")\n",
    "]\n",
    "\n",
    "# Total number of rows in the fold\n",
    "n_total_fold = (len(X_train) // n_cross_validation) * (n_cross_validation - 1)\n",
    "n_per_class = n_total_fold // 4\n",
    "\n",
    "# Undersampling strategy: only for classes larger than target_count\n",
    "undersample_dict = {\"CN\": n_per_class, \"LMCI\": n_per_class}\n",
    "\n",
    "# Oversampling strategy: only for classes smaller than target_count\n",
    "oversample_dict = {\"EMCI\": n_per_class, \"AD\": n_per_class}\n",
    "\n",
    "classifiers = {\n",
    "    'Decision Tree': Pipeline([\n",
    "        ('pre', preprocessing), \n",
    "        ('rus', RandomUnderSampler(sampling_strategy=undersample_dict, random_state=42)),\n",
    "        ('smotenc', SMOTENC(categorical_features=categorical_features, sampling_strategy=oversample_dict, random_state=42)),\n",
    "        ('clf', DecisionTreeClassifier(random_state=42, class_weight='balanced', max_depth=5))\n",
    "    ]),\n",
    "    'Random Forest': Pipeline([\n",
    "        ('pre', preprocessing),\n",
    "        ('rus', RandomUnderSampler(sampling_strategy=undersample_dict, random_state=42)),\n",
    "        ('smotenc', SMOTENC(categorical_features=categorical_features, sampling_strategy=oversample_dict, random_state=42)),\n",
    "        ('clf', RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1))\n",
    "    ]),\n",
    "    'Extra Trees': Pipeline([\n",
    "        ('pre', preprocessing),\n",
    "        ('rus', RandomUnderSampler(sampling_strategy=undersample_dict, random_state=42)),\n",
    "        ('smotenc', SMOTENC(categorical_features=categorical_features, sampling_strategy=oversample_dict, random_state=42)),\n",
    "        ('clf', ExtraTreesClassifier(random_state=42, class_weight='balanced', n_jobs=-1))\n",
    "    ]),\n",
    "    'Adaptive Boosting': Pipeline([\n",
    "        ('pre', preprocessing),\n",
    "        ('rus', RandomUnderSampler(sampling_strategy=undersample_dict, random_state=42)),\n",
    "        ('smotenc', SMOTENC(categorical_features=categorical_features, sampling_strategy=oversample_dict, random_state=42)),\n",
    "        ('clf', AdaBoostClassifier(random_state=42, estimator=DecisionTreeClassifier(class_weight='balanced')))\n",
    "    ]),\n",
    "    'Multinomial Logistic Regression': Pipeline([\n",
    "        ('pre', preprocessing),\n",
    "        ('scl', StandardScaler()),\n",
    "        ('rus', RandomUnderSampler(sampling_strategy=undersample_dict, random_state=42)),\n",
    "        ('smotenc', SMOTENC(categorical_features=categorical_features, sampling_strategy=oversample_dict, random_state=42)), \n",
    "        ('clf', LogisticRegression(random_state=42, solver='saga', max_iter=2000, class_weight='balanced'))\n",
    "    ])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we start the Grid Search (this will take a while). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running GridSearch for Decision Tree ...\n",
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
      "Best params for Decision Tree: {'clf__ccp_alpha': 0.0, 'clf__criterion': 'gini', 'clf__min_samples_leaf': 8, 'clf__min_samples_split': 2}\n",
      "Best f1_macro: 0.9007\n",
      "Decision Tree CV scores: [0.88899843 0.90211446 0.91595396 0.90893799 0.88748017]\n",
      "\n",
      "Running GridSearch for Random Forest ...\n",
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "Best params for Random Forest: {'clf__criterion': 'entropy', 'clf__max_depth': 6, 'clf__max_features': 1.0, 'clf__min_samples_leaf': 4, 'clf__n_estimators': 50}\n",
      "Best f1_macro: 0.9150\n",
      "Random Forest CV scores: [0.90787286 0.91139614 0.92945414 0.92783247 0.89843544]\n",
      "\n",
      "Running GridSearch for Extra Trees ...\n",
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "Best params for Extra Trees: {'clf__criterion': 'gini', 'clf__max_depth': None, 'clf__max_features': 1.0, 'clf__min_samples_leaf': 8, 'clf__n_estimators': 75}\n",
      "Best f1_macro: 0.9123\n",
      "Extra Trees CV scores: [0.89475062 0.91819697 0.92699772 0.93147852 0.89020888]\n",
      "\n",
      "Running GridSearch for Adaptive Boosting ...\n",
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "Best params for Adaptive Boosting: {'clf__estimator__criterion': 'gini', 'clf__estimator__max_depth': 4, 'clf__estimator__min_samples_leaf': 8, 'clf__learning_rate': 0.1, 'clf__n_estimators': 50}\n",
      "Best f1_macro: 0.9158\n",
      "Adaptive Boosting CV scores: [0.90554833 0.91711549 0.92907372 0.93601373 0.89122577]\n",
      "\n",
      "Running GridSearch for Multinomial Logistic Regression ...\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Best params for Multinomial Logistic Regression: {'clf__C': 1.0, 'clf__penalty': 'l1'}\n",
      "Best f1_macro: 0.8708\n",
      "Multinomial Logistic Regression CV scores: [0.8567666  0.86025577 0.87987926 0.8880455  0.8690957 ]\n"
     ]
    }
   ],
   "source": [
    "bmcs = run_gridsearch(X_train=X_train, y_train=y_train, pipelines=classifiers, param_grids=param_grids, cv = n_cross_validation, scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will choose this hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Sampling\n",
    "classifiers_1 = {\n",
    "    'Decision Tree': DecisionTreeClassifier(\n",
    "        random_state=42,\n",
    "        class_weight='balanced',\n",
    "        criterion='entropy',\n",
    "        max_depth=5,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=8,\n",
    "        ccp_alpha=0.005\n",
    "    ),\n",
    "\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        random_state=42,\n",
    "        class_weight='balanced',\n",
    "        n_jobs=-1,\n",
    "        criterion='entropy',\n",
    "        max_depth=6,\n",
    "        max_features=1.0,\n",
    "        min_samples_leaf=4,\n",
    "        n_estimators=100\n",
    "    ),\n",
    "\n",
    "    'Extra Trees': ExtraTreesClassifier(\n",
    "        random_state=42,\n",
    "        class_weight='balanced',\n",
    "        n_jobs=-1,\n",
    "        criterion='entropy',\n",
    "        max_depth=None,\n",
    "        max_features=1.0,\n",
    "        min_samples_leaf=4,\n",
    "        n_estimators=75\n",
    "    ),\n",
    "\n",
    "    'Adaptive Boosting': AdaBoostClassifier(\n",
    "        random_state=42,\n",
    "        estimator=DecisionTreeClassifier(\n",
    "            class_weight='balanced',\n",
    "            criterion='gini',\n",
    "            max_depth=4,\n",
    "            min_samples_leaf=4\n",
    "        ),\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=50\n",
    "    ),\n",
    "\n",
    "    'Multinomial Logistic Regression': Pipeline([\n",
    "        ('scl', StandardScaler()),\n",
    "        ('clf', LogisticRegression(\n",
    "            random_state=42,\n",
    "            solver='saga',\n",
    "            max_iter=2000,\n",
    "            class_weight='balanced',\n",
    "            penalty='l1',\n",
    "            C=0.1\n",
    "        ))\n",
    "    ])\n",
    "}\n",
    "\n",
    "\n",
    "# Sampling\n",
    "classifiers_2 = {\n",
    "    'Decision Tree Sampled': DecisionTreeClassifier(\n",
    "        random_state=42,\n",
    "        class_weight='balanced',\n",
    "        criterion='gini',\n",
    "        max_depth=5,  \n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=8,\n",
    "        ccp_alpha=0.0\n",
    "    ),\n",
    "\n",
    "    'Random Forest Sampled': RandomForestClassifier(\n",
    "        random_state=42,\n",
    "        class_weight='balanced',\n",
    "        n_jobs=-1,\n",
    "        criterion='entropy',\n",
    "        max_depth=6,\n",
    "        max_features=1.0,\n",
    "        min_samples_leaf=4,\n",
    "        n_estimators=50\n",
    "    ),\n",
    "\n",
    "    'Extra Trees Sampled': ExtraTreesClassifier(\n",
    "        random_state=42,\n",
    "        class_weight='balanced',\n",
    "        n_jobs=-1,\n",
    "        criterion='gini',\n",
    "        max_depth=None,\n",
    "        max_features=1.0,\n",
    "        min_samples_leaf=8,\n",
    "        n_estimators=75\n",
    "    ),\n",
    "\n",
    "    'Adaptive Boosting Sampled': AdaBoostClassifier(\n",
    "        random_state=42,\n",
    "        estimator=DecisionTreeClassifier(\n",
    "            class_weight='balanced',\n",
    "            criterion='gini',\n",
    "            max_depth=4,\n",
    "            min_samples_leaf=8\n",
    "        ),\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=50\n",
    "    ),\n",
    "\n",
    "    'Multinomial Logistic Regression Sampled': Pipeline([\n",
    "        ('scl', StandardScaler()),\n",
    "        ('clf', LogisticRegression(\n",
    "            random_state=42,\n",
    "            solver='saga',\n",
    "            max_iter=2000,\n",
    "            class_weight='balanced',\n",
    "            penalty='l1',\n",
    "            C=1.0\n",
    "        ))\n",
    "    ])\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
